{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# <b>Bayesian Logistic Regression - Metropolis-Hastings</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Aims\n",
    "<ul>\n",
    "<li>To implement the MH algorithm.</li>\n",
    "<li>To use it to compute classification probabilities.</li>\n",
    "</ul>\n",
    "<br><br>\n",
    "Let's start importing some useful modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy                 as np\n",
    "import matplotlib.pyplot     as plt\n",
    "import seaborn               as sns\n",
    "import plotly.plotly         as py\n",
    "import plotly.graph_objs     as go\n",
    "import scipy.io              as sio\n",
    "import pandas                as pd\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "from scipy         import optimize, linalg\n",
    "from pprint        import pprint\n",
    "from jupyterthemes import jtplot\n",
    "\n",
    "\n",
    "jtplot.style('grade3', context='notebook', fscale=1.4)\n",
    "jtplot.style(ticks=True, grid=False)\n",
    "jtplot.figsize(x=15, y=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Metropolis-Hastings\n",
    "In this lab, we’re going to implement the Metropolis-Hasting algorithm described in the lecture. Use the binary classification data binaryclass2.mat and the function laplacecomp. If you pass this function a 2-dimensional $\\mathbf{w}$ vector, it will return $g(\\mathbf{w};\\mathbf{X},\\mathbf{t},σ^2)$ and $logg(\\mathbf{w};\\mathbf{X},\\mathbf{t},σ^2)$. \n",
    "\n",
    "(Remember that $g(\\mathbf{w}; \\mathbf{X}, \\mathbf{t}, σ^2) \\propto p(\\mathbf{w}|\\mathbf{X}, \\mathbf{t}, σ^2)$, the posterior density of interest.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Posterior approximation\n",
    "\n",
    "Let's write and test the function to compute $g(\\mathbf{w}; \\mathbf{X}, \\mathbf{t}, σ^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def laplacecomp(w, X, t):\n",
    "    '''\n",
    "        Return two np array for g and log(g)\n",
    "    '''\n",
    "    w = np.array(w)\n",
    "    X = np.array(X)\n",
    "    t = np.array(t)\n",
    "\n",
    "    # Computes g and log g for the laplace model introduced in the lecture.\n",
    "    ss = 10 # Prior variance\n",
    "    # Evaluate log prior\n",
    "    logg = -(1/(2 * ss)) * w.transpose().dot(w)\n",
    "    # Compute P\n",
    "    P = np.array(1. / ( 1 + np.exp(-X.dot(w))))\n",
    "    #print(P)\n",
    "    logl = sum((t * np.log(P)) + ((1 - t) * np.log(1-P)))\n",
    "    \n",
    "    logg = logg + logl\n",
    "    g = np.exp(logg)\n",
    "    return (g[0][0], logg[0][0])\n",
    "\n",
    "w = np.array([[-1],[-2]])\n",
    "X = np.matrix([[0, 0], [1,1]])\n",
    "t = np.array([0,1])\n",
    "assert laplacecomp(w, X, t) == (0.37093273795143539, -0.99173453213368734), 'Error in laplacomp function'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Problem visualisation\n",
    "Let's start to work on our test case by importing the data and visualising the structure of this classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~srossi/2.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat = sio.loadmat('binaryclass2.mat')\n",
    "X = mat['X']\n",
    "t = mat['t']\n",
    "w = np.zeros([X.shape[1], 1])\n",
    "\n",
    "df = pd.DataFrame(X)\n",
    "df0 = pd.DataFrame(t)\n",
    "df.insert(2, 2, value=df0)\n",
    "\n",
    "trace1 = go.Scatter(x = df[df[2] == 0][0], y = df[df[2] == 0][1], mode = 'markers', name = 'Class 0')\n",
    "trace2 = go.Scatter(x = df[df[2] == 1][0], y = df[df[2] == 1][1], mode = 'markers', name = 'Class 1')\n",
    "data = [trace1, trace2]\n",
    "py.iplot(data, filename='basic-scatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's write our Metropolis-Hastings for MCMC sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def MH(X, t, total_trials, step):\n",
    "    s = 0\n",
    "    w = np.random.randn(2,1)\n",
    "    ws = [w, ] \n",
    "\n",
    "    for s in np.arange(total_trials):\n",
    "        #s += 1\n",
    "        if (s+1) % (total_trials/100) == 0:\n",
    "            if (s+1) % (total_trials/10) == 0:\n",
    "                print('|', end='')\n",
    "            else:\n",
    "                print('.', end='')\n",
    "                \n",
    "        wp = np.random.randn(2,1) * 0.5 + w \n",
    "        w = ws[-1]\n",
    "        gws, loggws = laplacecomp(w, X, t)\n",
    "        gwp, loggwp = laplacecomp(wp, X, t)\n",
    "        #compute acceptance ratio r\n",
    "        logr = loggwp - loggws\n",
    "        r = np.exp(logr)\n",
    "    \n",
    "        if logr >= 0:\n",
    "            ws.append(wp) #acceptance\n",
    "        else:\n",
    "            u = np.random.uniform(0,1)\n",
    "            if u <= r:\n",
    "                ws.append(wp) #acceptance\n",
    "            else:\n",
    "                ws.append(w) #rejection\n",
    "    print()\n",
    "    return ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's run our simulation 10000 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:15: RuntimeWarning:\n",
      "\n",
      "divide by zero encountered in log\n",
      "\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:15: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in multiply\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........|.........|.........|.........|.........|.........|.........|.........|.........|.........|\n"
     ]
    }
   ],
   "source": [
    "step = np.array([[0.5, 0], [0, 0.5]])\n",
    "num_trials = 20000\n",
    "samples = MH(X, t, num_trials, step)\n",
    "#pprint(samples[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~srossi/22.embed\" height=\"600px\" width=\"600px\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_df = pd.DataFrame([np.array(samples)[:,0][:,0], np.array(samples)[:,1][:,0]]).transpose()\n",
    "\n",
    "#colorscale = [ 'rgb(165,0,38)', 'rgb(215,48,39)', 'rgb(244,109,67)', 'rgb(253,174,97)', 'rgb(254,224,144)',\\\n",
    "#                'rgb(224,243,248)', 'rgb(171,217,233)', 'rgb(116,173,209)', 'rgb(69,117,180)',\\\n",
    "#                'rgb(49,54,149)']\n",
    "\n",
    "colorscale2 = [ 'rgb(165,0,38)',  'rgb(244,109,67)',  'rgb(254,224,144)',\\\n",
    "                 'rgb(171,217,233)',  'rgb(69,117,180)',\\\n",
    "                'rgb(49,54,149)']\n",
    "\n",
    "fig = ff.create_2d_density(\n",
    "    w_df[0], w_df[1], colorscale=colorscale2,\n",
    "    hist_color='rgb(255, 237, 222)', point_size=1\n",
    ")\n",
    "\n",
    "py.iplot(fig, filename='histogram_subplots')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This is the result of sampling done before. As we can clearly see, the strenght of this method is that can work without any prior assumption on the type of distribution as it's a non-parametric model for distribution density estimation.\n",
    "\n",
    "Now, the next thing to do is to predict the new label of a $x_{new}$ starting from this samples list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def predict(samples, x_new):\n",
    "    p = 0.\n",
    "    for w in samples:\n",
    "        p += 1 / (1 + np.exp(-w.T.dot(x_new)))\n",
    "    p /= len(samples)\n",
    "    return p[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23122952659698856"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_new = np.array([2,-4])\n",
    "predict(samples, x_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To have a more deep visualisation of the predictions, we can plot the probability for a point to be assigned to class 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "xmin, xmax, xstep = (-6, 6.5, 0.5)\n",
    "ymin, ymax, ystep = (-6, 6.5, 0.5)\n",
    "\n",
    "p = []\n",
    "for y in np.arange(ymin, ymax, ystep):\n",
    "    p_x = []\n",
    "    for x in np.arange(xmin, xmax, xstep):\n",
    "        x_new = np.array([x, y])\n",
    "        p_x.append(predict(samples, x_new))\n",
    "    p.append(p_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~srossi/18.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = [go.Contour(\n",
    "            z=p,\n",
    "            y=np.arange(xmin, xmax, xstep),\n",
    "            x=np.arange(ymin, ymax, ystep),\n",
    "            contours=dict(coloring='heatmap')\n",
    "    ), go.Scatter(\n",
    "        x = df[df[2] == 0][0],\n",
    "        y = df[df[2] == 0][1],\n",
    "        mode = 'markers',\n",
    "        marker = dict(color='orange'),\n",
    "        name = 'Class 0'\n",
    "    ), go.Scatter(\n",
    "        x = df[df[2] == 1][0],\n",
    "        y = df[df[2] == 1][1],\n",
    "        mode = 'markers',\n",
    "        marker = dict(color='blue'),\n",
    "        name = 'Class 1'\n",
    ")]\n",
    "\n",
    "py.iplot(prob, filename='contour-scatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "This is very interesting for a couple of reason:\n",
    "- we achived a non-linear classification without using non-linear decision rule\n",
    "- our belif on the label follows with less uncertanty the space region where the training data lays."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
